{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final-posting-sentiment-link.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPSWT0KkjmsualgWisGieJ1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jNh9ecnY2VtZ"},"source":["# Linking Postings to Recognized Emotions [Script C]"]},{"cell_type":"markdown","metadata":{"id":"8L8iwskb2eFf"},"source":["*This script links emotions recognized in reviews made about companies, to job postings that were made by the same company within the same time range. Here, we pick time ranges of six months because companies tend to hold semi-annual reviews. At the end of this script, we get the top three emotions for each company and time range and drop all information related to the company and the time range. This results in the dataset that will be used to train our multi-label classification model in Script C*"]},{"cell_type":"markdown","metadata":{"id":"SVMRWwbi4d7y"},"source":["## Package Installations, Imports & Setup\n","\n"]},{"cell_type":"code","metadata":{"id":"Yke_g_FP2I47"},"source":["import pandas as pd\n","import numpy as np\n","import re\n","\n","import io\n","from google.colab import files"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-8ryCSbQ8LJd"},"source":["## Data Import & Processing"]},{"cell_type":"code","metadata":{"id":"8Xxfnu6J4rav"},"source":["# Import review sentiments from Script B\n","reviews = pd.read_csv(\"review_sentiments.csv\")\n","reviews.drop_duplicates(inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5DFF_WFd5REx"},"source":["# Method takes in sentiment list with percentages and flattens it into a simple list\n","def flatten_sentiments(sent_list):\n","  sentiments = []\n","  for sent in sent_list:\n","    sentiments.append(sent.get('sentiment'))\n","  return sentiments"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ummNp2-h6bYp"},"source":["# Add column with flattened review\n","reviews['sent_list'] = reviews['sentiments'].apply(lambda x: flatten_sentiments(eval(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I55j9VUS67p7"},"source":["# Turn dataframe into multilabel dataset, with a column for each emotion\n","SENTIMENT_LABELS = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n","\n","for SENTIMENT in SENTIMENT_LABELS:\n","  reviews[SENTIMENT] = reviews['sent_list'].apply(lambda x: SENTIMENT in x)\n","  reviews[SENTIMENT] = reviews[SENTIMENT].astype(int)\n","\n","KEEP_COLUMNS = ['company', 'date'] + SENTIMENT_LABELS\n","review_sentiments = reviews[KEEP_COLUMNS].copy()\n","\n","# Reformat date column to be of date type\n","review_sentiments['date'] = review_sentiments['date'].apply(lambda x: pd.to_datetime(x, format='%b %d, %Y '))\n","review_sentiments.sort_values(by='date', inplace=True)\n","review_sentiments.reset_index(drop=True, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ee7V9yMF7fZ8"},"source":["# Define six-month date ranges\n","date_rng = pd.date_range(start=min(review_sentiments['date']), end=max(review_sentiments['date']), freq='6M')\n","date_rng = date_rng.insert(27, max(review_sentiments['date']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r0925ui27kHG"},"source":["# Method takes in date and returns time period it is in\n","def find_period(curr_date):\n","  period = 0\n","  for period in range(28):\n","    if curr_date <= date_rng[period]:\n","      return period+1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"597CPYPq73Ps"},"source":["# Match each row to corresponding period according to date range and drop date\n","review_sentiments['period'] = review_sentiments['date'].apply(lambda x: find_period(x))\n","review_sentiments.drop(columns=['date'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkPOyX5m74-l"},"source":["# Sum up emotions by company and time period\n","company_sentiments = review_sentiments.groupby(['company','period'], as_index=False).sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7vns2oQo8U-1"},"source":["## Matching Postings and Emotions"]},{"cell_type":"code","metadata":{"id":"XoeONG4f8C1R"},"source":["# Method returns dataframe with top 3 emotions per row\n","\n","def get_top_3_exclude_0(df):\n","  #Create new dataframe to store top sentiments\n","  top_sentiments = pd.DataFrame(np.empty, index = np.arange(len(df)), columns = ['listing','1st Sent', '2nd Sent', '3rd Sent'])\n","  #Duplicate initial dataframe and drop listing so idxmax can be used\n","  df2 = df.drop(columns=['listing'])\n","  for j in range(1,4):\n","    for index, row in df2.iterrows():\n","      top_sent = row.idxmax()\n","      #print(top_sent)\n","      #print(index)\n","      top_sentiments.iloc[index]['listing'] = df.iloc[index]['listing']\n","      top_sentiments.iloc[index][j] = top_sent\n","      df2.iloc[index][top_sent] = np.nan\n","  return top_sentiments"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-Azd79N8w-t"},"source":["# Import postings dataframe\n","postings = pd.read_csv(\"postings.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R1oLtxip89F2"},"source":["# Merge posting dataset and emotion dataset on company and time period\n","posting_sentiments = postings.merge(company_sentiments, how='left', left_on=[\"companyName\", \"period\"], right_on=[\"company\",\"period\"])\n","posting_sentiments.dropna(subset = [\"company\"], inplace=True)\n","posting_sentiments[SENTIMENT_LABELS] = posting_sentiments[SENTIMENT_LABELS].replace(['0', 0], np.nan)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xwXxxWl99LVZ"},"source":["# Drop all columns but the listing content and the emotion labels\n","KEEP_COLUMNS = ['listing_jobDesc'] + SENTIMENT_LABELS\n","posting_sentiments = posting_sentiments[KEEP_COLUMNS].copy()\n","posting_sentiments.reset_index(drop=True, inplace=True)\n","posting_sentiments.rename(columns={\"listing_jobDesc\": \"listing\"}, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jhCO46cW9af6"},"source":["# Get top sentiments per posting\n","top_sentiments = get_top_3_exclude_0(posting_sentiments)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_50nb119mMK"},"source":["# Combine top 3 emotions into tag columns\n","top_sentiments['tags'] = top_sentiments.apply(lambda row: [row['1st Sent'], row['2nd Sent'], row['3rd Sent']], axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g-iZQ1HB9nHs"},"source":["def isNaN(string):\n","    return string != string"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R4Mg_Zfa9pKH"},"source":["# Method to remove all nan values\n","def remove_if_present(my_list):\n","  for item in my_list:\n","    if(isNaN(item)):\n","      my_list.remove(item)\n","  return my_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TPCZbF3f-FS7"},"source":["# Remove all nan values from tags column\n","top_sentiments['tags'] = top_sentiments.apply(lambda row: remove_if_present(row['tags']), axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"07jrNkMd-LYu"},"source":["# Export dataframe for next script\n","top_sentiments.to_csv('top_sentiments.csv') \n","files.download('top_sentiments.csv')"],"execution_count":null,"outputs":[]}]}